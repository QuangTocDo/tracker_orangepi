import cv2
import queue
import threading
import asyncio
import sys
import os
import numpy as np
import time
from collections import deque
import yaml
from types import SimpleNamespace
import torch

# --- C√ÅC IMPORT M·ªöI CHO RKNN V√Ä TRACKER ---
try:
    from rknnlite.api import RKNNLite
    from ultralytics.trackers.bot_sort import BOTSORT
except ImportError as e:
    print(f"L·ªói import th∆∞ vi·ªán: {e}")
    print("H√£y ch·∫Øc ch·∫Øn b·∫°n ƒë√£ c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt (rknn-toolkit2, ultralytics, pyyaml, torch) v√† m√¥i tr∆∞·ªùng ƒë√£ ƒë∆∞·ª£c k√≠ch ho·∫°t.")
    sys.exit(1)


# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N (GI·ªÆ NGUY√äN) ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
if BASE_DIR not in sys.path:
    sys.path.append(BASE_DIR)
UTILS_DIR = os.path.join(BASE_DIR, 'utils')
if UTILS_DIR not in sys.path:
    sys.path.append(UTILS_DIR)

# --- IMPORT C√ÅC MODULE HI·ªÜN C√ì (GI·ªÆ NGUY√äN) ---
import config
from analyzer import Analyzer as ReidFaceAnalyzer
from attributes_analyzer import AttributesAnalyzer
from vector_database import VectorDatabase_Manager
from tracker import TrackManager
from draw import draw_tracked_objects

# ===================================================================
# ==========     L·ªöP V√Ä H√ÄM H·ªñ TR·ª¢ CHO RKNN & TRACKER    ==========
# ===================================================================

class MockResults(SimpleNamespace):
    """
    L·ªõp gi·∫£ l·∫≠p ƒë·ªëi t∆∞·ª£ng Results c·ªßa Ultralytics ƒë·ªÉ cung c·∫•p ƒë·∫ßu v√†o cho BoTSORT.
    """
    def __getitem__(self, idx):
        new_results = MockResults()
        new_results.orig_shape = self.orig_shape
        
        new_boxes = SimpleNamespace()
        new_boxes.xyxy = self.boxes.xyxy[idx]
        new_boxes.conf = self.boxes.conf[idx]
        new_boxes.cls = self.boxes.cls[idx]
        
        new_results.boxes = new_boxes
        new_results.conf = new_boxes.conf
        
        if hasattr(self, 'xywh'):
            new_results.xywh = self.xywh[idx]
        if hasattr(self, 'cls'):
            new_results.cls = self.cls[idx]
            
        return new_results
    
    def __len__(self):
        return len(self.boxes.xyxy)

def preprocess(frame, input_size=(640, 640)):
    """Chu·∫©n b·ªã frame ·∫£nh cho ƒë·∫ßu v√†o c·ªßa m√¥ h√¨nh RKNN."""
    img = cv2.resize(frame, input_size)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = np.expand_dims(img, axis=0)
    return img

def postprocess(outputs, orig_shape, conf_threshold=0.5, nms_threshold=0.6):
    """Gi·∫£i m√£ ƒë·∫ßu ra t·ª´ m√¥ h√¨nh YOLO ch·∫°y tr√™n RKNN."""
    orig_h, orig_w = orig_shape
    input_h, input_w = (640, 640)
    predictions = np.squeeze(outputs[0]).T
    
    class_scores = predictions[:, 4:]
    max_scores = np.max(class_scores, axis=1)
    class_ids = np.argmax(class_scores, axis=1)
    
    # L·ªçc theo class 'person' (class_id = 0) v√† ng∆∞·ª°ng tin c·∫≠y
    person_class_mask = class_ids == 0
    conf_mask = max_scores > conf_threshold
    valid_mask = person_class_mask & conf_mask
    
    valid_predictions = predictions[valid_mask]
    if len(valid_predictions) == 0:
        return [], [], []
        
    valid_scores = max_scores[valid_mask]
    valid_class_ids = class_ids[valid_mask]
    
    x, y, w, h = valid_predictions[:, 0], valid_predictions[:, 1], valid_predictions[:, 2], valid_predictions[:, 3]
    x_factor = orig_w / input_w
    y_factor = orig_h / input_h
    
    left = ((x - 0.5 * w) * x_factor)
    top = ((y - 0.5 * h) * y_factor)
    width = (w * x_factor)
    height = (h * y_factor)
    
    boxes = np.column_stack((left, top, width, height))
    indices = cv2.dnn.NMSBoxes(boxes.tolist(), valid_scores.tolist(), conf_threshold, nms_threshold)
    
    final_boxes, final_scores, final_class_ids = [], [], []
    if len(indices) > 0:
        for i in indices.flatten():
            l, t, w, h = boxes[i]
            final_boxes.append([int(l), int(t), int(l + w), int(t + h)])
            final_scores.append(valid_scores[i])
            final_class_ids.append(valid_class_ids[i])
            
    return final_boxes, final_scores, final_class_ids

# ===================================================================
# ========== C√ÅC H√ÄM WORKER ƒêA LU·ªíNG (GI·ªÆ NGUY√äN) =========
# ===================================================================

def is_image_quality_good(image, min_size=(64, 128), blur_threshold=80.0):
    if image is None or image.size == 0: return False
    h, w, _ = image.shape
    if w < min_size[0] or h < min_size[1]: return False
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    if cv2.Laplacian(gray, cv2.CV_64F).var() < blur_threshold: return False
    return True

def reid_face_worker(task_queue, result_queue, analyzer):
    """Worker cho lu·ªìng 1: Tr√≠ch xu·∫•t vector Re-ID v√† Face."""
    print("üöÄ Worker Re-ID/Face ƒë√£ b·∫Øt ƒë·∫ßu.")
    while True:
        try:
            track_id, image_crop = task_queue.get(block=True)
            if not is_image_quality_good(image_crop):
                task_queue.task_done()
                continue
            reid_vector = analyzer.extract_reid_feature(image_crop)
            face_vector, face_confidence = analyzer.extract_face_feature(image_crop)
            result_queue.put((track_id, reid_vector, face_vector, face_confidence))
            task_queue.task_done()
        except Exception as e:
            print(f"L·ªói trong worker Re-ID/Face: {e}")

def attribute_analysis_worker(task_queue, result_queue, analyzer):
    """Worker cho lu·ªìng 2: Ph√¢n t√≠ch thu·ªôc t√≠nh (gi·ªõi t√≠nh, qu·∫ßn √°o)."""
    print("üöÄ Worker ph√¢n t√≠ch thu·ªôc t√≠nh ƒë√£ b·∫Øt ƒë·∫ßu.")
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    while True:
        try:
            track_id, frame, bbox = task_queue.get(block=True)
            analysis_result = loop.run_until_complete(
                analyzer.analyze_person_by_bbox(frame, bbox, track_id)
            )
            result_queue.put((track_id, analysis_result))
            task_queue.task_done()
        except Exception as e:
            print(f"L·ªói trong worker ph√¢n t√≠ch thu·ªôc t√≠nh: {e}")

# ===================================================================
# ==========              H√ÄM MAIN ƒê√É ƒê∆Ø·ª¢C N√ÇNG C·∫§P            ==========
# ===================================================================

def main():
    print("--- B·∫ÆT ƒê·∫¶U H·ªÜ TH·ªêNG TRACKING & PH√ÇN T√çCH (RKNN Accelerated) ---")
    db_manager = None
    rknn = None
    cap = None
    try:
        # --- 1. Kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn logic (GI·ªÆ NGUY√äN) ---
        db_manager = VectorDatabase_Manager()
        reid_face_analyzer = ReidFaceAnalyzer(face_model_name="deepface")
        attributes_analyzer = AttributesAnalyzer()
        print("ƒêang t·∫£i models cho ph√¢n t√≠ch thu·ªôc t√≠nh, vui l√≤ng ƒë·ª£i...")
        asyncio.run(attributes_analyzer.load_models())
        print("‚úÖ T·∫£i models thu·ªôc t√≠nh ho√†n t·∫•t.")

        last_id = db_manager.get_max_person_id()
        track_manager = TrackManager(reid_face_analyzer, db_manager)
        track_manager.next_person_id = last_id + 1
        print(f"‚úÖ ID l·ªõn nh·∫•t trong CSDL: {last_id}. ID ti·∫øp theo: {last_id + 1}.")

        # --- 2. Thi·∫øt l·∫≠p x·ª≠ l√Ω ƒëa lu·ªìng (GI·ªÆ NGUY√äN) ---
        reid_task_queue = queue.Queue(maxsize=200)
        reid_result_queue = queue.Queue()
        reid_worker = threading.Thread(
            target=reid_face_worker, args=(reid_task_queue, reid_result_queue, reid_face_analyzer), daemon=True
        )
        reid_worker.start()

        attribute_task_queue = queue.Queue(maxsize=100)
        attribute_result_queue = queue.Queue()
        attribute_worker = threading.Thread(
            target=attribute_analysis_worker, args=(attribute_task_queue, attribute_result_queue, attributes_analyzer), daemon=True
        )
        attribute_worker.start()

        # --- 3. THAY TH·∫æ: Kh·ªüi t·∫°o RKNN v√† Tracker BoTSORT ---
        if not os.path.exists(config.RKNN_MODEL_PATH):
            print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file model RKNN t·∫°i: {config.RKNN_MODEL_PATH}")
            print("Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n trong file config.py")
            sys.exit(1)
        if not os.path.exists(config.TRACKER_CONFIG_PATH):
            print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file c·∫•u h√¨nh tracker t·∫°i: {config.TRACKER_CONFIG_PATH}")
            sys.exit(1)
        
        rknn = RKNN()
        print("--> ƒêang t·∫£i model RKNN...")
        ret = rknn.load_rknn(config.RKNN_MODEL_PATH)
        if ret != 0:
            print(f"‚ùå T·∫£i model RKNN th·∫•t b·∫°i! (M√£ l·ªói: {ret})")
            exit(ret)
        print("‚úÖ T·∫£i model th√†nh c√¥ng.")

        print("--> Kh·ªüi t·∫°o RKNN runtime...")
        ret = rknn.init_runtime(target="rk3588") # ƒê·∫£m b·∫£o target ph√π h·ª£p v·ªõi ph·∫ßn c·ª©ng c·ªßa b·∫°n
        if ret != 0:
            print(f"‚ùå Kh·ªüi t·∫°o runtime th·∫•t b·∫°i! (M√£ l·ªói: {ret})")
            exit(ret)
        print("‚úÖ Kh·ªüi t·∫°o runtime th√†nh c√¥ng.")

        print("--> Kh·ªüi t·∫°o tracker BoTSORT...")
        with open(config.TRACKER_CONFIG_PATH, "r") as f:
            tracker_config = yaml.safe_load(f)
        args = SimpleNamespace(**tracker_config)
        tracker = BOTSORT(args=args, frame_rate=30)
        print("‚úÖ Kh·ªüi t·∫°o tracker th√†nh c√¥ng.")

        # --- 4. THAY TH·∫æ: M·ªü ngu·ªìn video th·ªß c√¥ng ---
        cap = cv2.VideoCapture(0) # Ho·∫∑c ƒë∆∞·ªùng d·∫´n file video
        if not cap.isOpened():
            print("‚ùå L·ªói: Kh√¥ng th·ªÉ m·ªü camera ho·∫∑c ngu·ªìn video.")
            return

        print("\n‚úÖ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng. B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video...")
        prev_time = 0
        # --- V√íNG L·∫∂P CH√çNH ƒê√É ƒê∆Ø·ª¢C T√ÅI C·∫§U TR√öC ---
        while True:
            ret, frame = cap.read()
            if not ret:
                print("L·ªói: Kh√¥ng th·ªÉ nh·∫≠n frame. K·∫øt th√∫c...")
                break

            # B∆Ø·ªöC 1: SUY LU·∫¨N V·ªöI RKNN
            img_in = preprocess(frame)
            outputs = rknn.inference(inputs=[img_in])
            
            # B∆Ø·ªöC 2: H·∫¨U X·ª¨ L√ù K·∫æT QU·∫¢
            raw_bboxes, raw_scores, raw_cls_ids = postprocess(outputs, frame.shape[:2], conf_threshold=0.35)

            # B∆Ø·ªöC 3: ƒê√ìNG G√ìI K·∫æT QU·∫¢ V√Ä C·∫¨P NH·∫¨T TRACKER
            results = MockResults()
            results.orig_shape = frame.shape[:2]
            
            boxes_ns = SimpleNamespace()
            boxes_ns.xyxy = torch.tensor(raw_bboxes, dtype=torch.float32)
            boxes_ns.conf = torch.tensor(raw_scores, dtype=torch.float32)
            boxes_ns.cls = torch.tensor(raw_cls_ids, dtype=torch.float32)
            results.boxes = boxes_ns
            results.conf = boxes_ns.conf
            results.cls = boxes_ns.cls
            
            # Tracker y√™u c·∫ßu ƒë·ªãnh d·∫°ng xywh
            xyxy = results.boxes.xyxy
            if xyxy.numel() > 0:
                x1, y1, x2, y2 = xyxy[:, 0], xyxy[:, 1], xyxy[:, 2], xyxy[:, 3]
                w, h = x2 - x1, y2 - y1
                cx, cy = x1 + w / 2, y1 + h / 2
                results.xywh = torch.stack((cx, cy, w, h), dim=1)
            else:
                results.xywh = torch.empty((0, 4), dtype=torch.float32)
            
            online_targets = tracker.update(results, frame)

            # B∆Ø·ªöC 4: CHU·∫®N B·ªä D·ªÆ LI·ªÜU CHO C√ÅC LU·ªíNG PH√ÇN T√çCH
            track_ids, bboxes = [], []
            if online_targets is not None and len(online_targets) > 0:
                for target in online_targets:
                    x1, y1, x2, y2, track_id, score, cls_id = target[:7]
                    bbox = [int(x1), int(y1), int(x2), int(y2)]
                    # L·ªçc theo di·ªán t√≠ch bbox nh∆∞ logic c≈©
                    bbox_area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
                    if config.MIN_BBOX_AREA < bbox_area < config.MAX_BBOX_AREA:
                        track_ids.append(int(track_id))
                        bboxes.append(bbox)

            # --- C√ÅC B∆Ø·ªöC X·ª¨ L√ù PH√çA SAU GI·ªÆ NGUY√äN ---
            track_manager.update_tracks(track_ids, bboxes, frame, reid_task_queue, attribute_task_queue)
            track_manager.process_analysis_results(reid_result_queue)
            track_manager.process_attribute_results(attribute_result_queue)
            
            frame_with_drawings = draw_tracked_objects(frame, track_manager.tracked_objects)
            # --- T√çNH TO√ÅN V√Ä HI·ªÇN TH·ªä FPS ---
            current_time = time.time()
            # Th√™m 1e-9 ƒë·ªÉ tr√°nh l·ªói chia cho 0 ·ªü frame ƒë·∫ßu ti√™n
            fps = 1 / (current_time - prev_time + 1e-9) 
            prev_time = current_time

            # Chu·∫©n b·ªã text ƒë·ªÉ v·∫Ω l√™n frame
            fps_text = f"FPS: {fps:.2f}"

            # V·∫Ω text FPS l√™n g√≥c tr√™n b√™n tr√°i c·ªßa frame ƒë√£ c√≥ c√°c h√¨nh v·∫Ω
            cv2.putText(frame_with_drawings, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)
            cv2.imshow("Tracking & Analysis System (RKNN Accelerated)", frame_with_drawings)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    
    except Exception as e:
        import traceback
        print(f"L·ªói nghi√™m tr·ªçng trong lu·ªìng ch√≠nh: {e}")
        traceback.print_exc()
    finally:
        # --- Gi·∫£i ph√≥ng t√†i nguy√™n ---
        if cap:
            cap.release()
        if rknn:
            rknn.release()
        if db_manager:
            db_manager.save_all_databases()
        cv2.destroyAllWindows()
        print("--- H·ªÜ TH·ªêNG ƒê√É D·ª™NG ---")

if __name__ == "__main__":
    main()
