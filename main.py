'''
# import cv2
# import queue
# import threading
# import asyncio
# import sys
# import os
# import numpy as np
# from ultralytics import YOLO
# import zmq # [THAY ƒê·ªîI] Th√™m th∆∞ vi·ªán ZMQ
# import time # [TH√äM V√ÄO]
# # --- C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n ---
# BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# if BASE_DIR not in sys.path:
#     sys.path.append(BASE_DIR)
# # Th√™m th∆∞ m·ª•c utils v√†o path n·∫øu c·∫ßn
# UTILS_DIR = os.path.join(BASE_DIR, 'utils')
# if UTILS_DIR not in sys.path:
#     sys.path.append(UTILS_DIR)

# import config
# from analyzer import Analyzer as ReidFaceAnalyzer
# from attributes_analyzer import AttributesAnalyzer
# from vector_database import VectorDatabase_Manager
# from tracker import TrackManager
# from draw import draw_tracked_objects

# # --- [THAY ƒê·ªîI] C·∫•u h√¨nh ZMQ v√† X·ª≠ l√Ω Frame ---
# ZMQ_IP = "localhost"
# ZMQ_PORT = 5555
# FRAME_QUEUE_MAX_SIZE = 100  # Gi·ªõi h·∫°n s·ªë frame trong h√†ng ƒë·ª£i
# FRAME_SKIP_RATE = 3        # Ch·ªâ x·ª≠ l√Ω 1 tr√™n m·ªói 2 frame nh·∫≠n ƒë∆∞·ª£c. ƒê·∫∑t l√† 1 ƒë·ªÉ x·ª≠ l√Ω t·∫•t c·∫£.

# # --- C√°c h√†m worker v√† ti·ªán √≠ch (Kh√¥ng thay ƒë·ªïi) ---
# def is_image_quality_good(image, min_size=(64, 128), blur_threshold=80.0):
#     if image is None or image.size == 0: return False
#     h, w, _ = image.shape
#     if w < min_size[0] or h < min_size[1]: return False
#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
#     if cv2.Laplacian(gray, cv2.CV_64F).var() < blur_threshold: return False
#     return True

# def reid_face_worker(task_queue, result_queue, analyzer):
#     """Worker cho lu·ªìng 1: Tr√≠ch xu·∫•t vector Re-ID v√† Face."""
#     print("üöÄ Worker Re-ID/Face ƒë√£ b·∫Øt ƒë·∫ßu.")
#     while True:
#         try:
#             track_id, image_crop = task_queue.get(block=True, timeout=1)
#             if not is_image_quality_good(image_crop):
#                 task_queue.task_done()
#                 continue
#             reid_vector = analyzer.extract_reid_feature(image_crop)
#             face_vector, face_confidence = analyzer.extract_face_feature(image_crop)
#             result_queue.put((track_id, reid_vector, face_vector, face_confidence))
#             task_queue.task_done()
#         except queue.Empty:
#             continue
#         except Exception as e:
#             print(f"L·ªói trong worker Re-ID/Face: {e}")

# def attribute_analysis_worker(task_queue, result_queue, analyzer):
#     """Worker cho lu·ªìng 2: Ph√¢n t√≠ch thu·ªôc t√≠nh (gi·ªõi t√≠nh, qu·∫ßn √°o)."""
#     print("üöÄ Worker ph√¢n t√≠ch thu·ªôc t√≠nh ƒë√£ b·∫Øt ƒë·∫ßu.")
#     loop = asyncio.new_event_loop()
#     asyncio.set_event_loop(loop)
#     while True:
#         try:
#             track_id, frame, bbox = task_queue.get(block=True, timeout=1)
#             analysis_result = loop.run_until_complete(
#                 analyzer.analyze_person_by_bbox(frame, bbox, track_id)
#             )
#             result_queue.put((track_id, analysis_result))
#             task_queue.task_done()
#         except queue.Empty:
#             continue
#         except Exception as e:
#             print(f"L·ªói trong worker ph√¢n t√≠ch thu·ªôc t√≠nh: {e}")

# # --- [THAY ƒê·ªîI] Lu·ªìng nh·∫≠n d·ªØ li·ªáu t·ª´ ZMQ ---
# def network_receiver_worker(context, stop_event, frame_queue):
#     """
#     Lu·ªìng chuy√™n nh·∫≠n d·ªØ li·ªáu t·ª´ ZMQ v√† ƒë·∫©y v√†o h√†ng ƒë·ª£i.
#     T√≠ch h·ª£p logic b·ªè qua frame (frame skipping).
#     """
#     socket = context.socket(zmq.SUB)
#     socket.connect(f"tcp://{ZMQ_IP}:{ZMQ_PORT}")
#     socket.setsockopt_string(zmq.SUBSCRIBE, '')
    
#     print(f"‚úÖ [Lu·ªìng M·∫°ng] ƒê√£ k·∫øt n·ªëi t·ªõi tcp://{ZMQ_IP}:{ZMQ_PORT} v√† ƒëang l·∫Øng nghe...")
    
#     frame_counter = 0
    
#     while not stop_event.is_set():
#         try:
#             if socket.poll(timeout=100): # Ch·ªù 100ms
#                 image_bytes = socket.recv() # Ch·ªâ nh·∫≠n ·∫£nh, kh√¥ng c·∫ßn frame_id
#                 frame_counter += 1

#                 if frame_counter % FRAME_SKIP_RATE == 0:
#                     try:
#                         frame_queue.put_nowait(image_bytes)
#                     except queue.Full:
#                         print(f"‚ö†Ô∏è [Lu·ªìng M·∫°ng] H√†ng ƒë·ª£i frame ƒë·∫ßy. B·ªè qua frame.")
        
#         except zmq.ZMQError as e:
#             print(f"‚ùå [Lu·ªìng M·∫°ng] L·ªói ZMQ: {e}")
#             break
#         except Exception as e:
#             print(f"‚ùå [Lu·ªìng M·∫°ng] L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}")
#             break
            
#     print("üõë [Lu·ªìng M·∫°ng] ƒêang d·ª´ng...")
#     socket.close()

# # --- [THAY ƒê·ªîI] H√†m x·ª≠ l√Ω ch√≠nh ƒë∆∞·ª£c t√°i c·∫•u tr√∫c t·ª´ h√†m main() c≈© ---
# def processing_loop(frame_queue, stop_event):
#     """
#     Lu·ªìng chuy√™n x·ª≠ l√Ω ·∫£nh: l·∫•y ·∫£nh t·ª´ h√†ng ƒë·ª£i, ch·∫°y model,
#     v√† th·ª±c hi·ªán c√°c t√°c v·ª• ph√¢n t√≠ch.
#     """
#     print("--- [Lu·ªìng X·ª≠ L√Ω] B·∫ÆT ƒê·∫¶U H·ªÜ TH·ªêNG TRACKING & PH√ÇN T√çCH ---")
#     db_manager = None
#     try:
#         # --- 1. Kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn ---
#         db_manager = VectorDatabase_Manager()
#         reid_face_analyzer = ReidFaceAnalyzer(face_model_name="mobilefacenet")
#         attributes_analyzer = AttributesAnalyzer()
#         print("[Lu·ªìng X·ª≠ L√Ω] ƒêang t·∫£i models cho ph√¢n t√≠ch thu·ªôc t√≠nh, vui l√≤ng ƒë·ª£i...")
#         asyncio.run(attributes_analyzer.load_models())
#         print("‚úÖ [Lu·ªìng X·ª≠ L√Ω] T·∫£i models thu·ªôc t√≠nh ho√†n t·∫•t.")

#         last_id = db_manager.get_max_person_id()
#         track_manager = TrackManager(reid_face_analyzer, db_manager)
#         track_manager.next_person_id = last_id + 1
#         print(f"‚úÖ ID l·ªõn nh·∫•t trong CSDL: {last_id}. ID ti·∫øp theo: {last_id + 1}.")

#         # --- 2. Thi·∫øt l·∫≠p x·ª≠ l√Ω ƒëa lu·ªìng cho c√°c worker ph√¢n t√≠ch ---
#         reid_task_queue = queue.Queue(maxsize=100)
#         reid_result_queue = queue.Queue()
#         reid_worker = threading.Thread(target=reid_face_worker, args=(reid_task_queue, reid_result_queue, reid_face_analyzer), daemon=True)
#         reid_worker.start()

#         attribute_task_queue = queue.Queue(maxsize=50)
#         attribute_result_queue = queue.Queue()
#         attribute_worker = threading.Thread(target=attribute_analysis_worker, args=(attribute_task_queue, attribute_result_queue, attributes_analyzer), daemon=True)
#         attribute_worker.start()

#         # --- 3. Load model YOLO ---
#         model = YOLO(config.YOLO_MODEL_PATH)
        
#         print("\n‚úÖ [Lu·ªìng X·ª≠ L√Ω] H·ªá th·ªëng ƒë√£ s·∫µn s√†ng. Ch·ªù frame t·ª´ ZMQ...")
        
#         # --- [THAY ƒê·ªîI] V√≤ng l·∫∑p ch√≠nh: L·∫•y frame t·ª´ queue v√† x·ª≠ l√Ω ---
#         while not stop_event.is_set():
#             try:
#                 # L·∫•y frame t·ª´ h√†ng ƒë·ª£i, c√≥ timeout ƒë·ªÉ kh√¥ng b·ªã block m√£i m√£i
#                 image_bytes = frame_queue.get(timeout=1.0)
                
#                 # Gi·∫£i m√£ ·∫£nh
#                 np_array = np.frombuffer(image_bytes, dtype=np.uint8)
#                 frame = cv2.imdecode(np_array, cv2.IMREAD_COLOR)

#                 if frame is None:
#                     print("‚ö†Ô∏è [Lu·ªìng X·ª≠ L√Ω] Kh√¥ng th·ªÉ gi·∫£i m√£ frame, b·ªè qua.")
#                     continue

#                 # Ch·∫°y model tr√™n m·ªôt frame duy nh·∫•t
#                 results = model.track(source=frame, show=False, conf=0.5, verbose=False, iou=0.5, classes=[0], tracker=config.TRACKER_CONFIG_PATH, stream=False, persist=True)
                
#                 # V√¨ ch·ªâ x·ª≠ l√Ω 1 frame, v√≤ng l·∫∑p n√†y th·ª±c ch·∫•t ch·ªâ ch·∫°y 1 l·∫ßn
#                 for result in results:
#                     track_ids, bboxes = [], []
#                     if result.boxes.id is not None:
#                         original_track_ids = result.boxes.id.int().cpu().tolist()
#                         original_bboxes = result.boxes.xyxy.cpu().tolist()
#                         for track_id, bbox in zip(original_track_ids, original_bboxes):
#                             if (bbox[2] - bbox[0]) * (bbox[3] - bbox[1]) > config.MIN_BBOX_AREA and (bbox[2] - bbox[0]) * (bbox[3] - bbox[1]) < config.MAX_BBOX_AREA:
#                                 track_ids.append(track_id)
#                                 bboxes.append(bbox)

#                     track_manager.update_tracks(track_ids, bboxes, frame, reid_task_queue, attribute_task_queue)
#                     track_manager.process_analysis_results(reid_result_queue)
#                     track_manager.process_attribute_results(attribute_result_queue)
                    
#                     frame_with_drawings = draw_tracked_objects(frame, track_manager.tracked_objects)
#                     cv2.imshow("Tracking & Analysis System", frame_with_drawings)

#                 if cv2.waitKey(1) & 0xFF == ord('q'):
#                     print("‚ÑπÔ∏è Nh·∫•n 'q', g·ª≠i t√≠n hi·ªáu d·ª´ng...")
#                     stop_event.set() # G·ª≠i t√≠n hi·ªáu d·ª´ng cho t·∫•t c·∫£ c√°c lu·ªìng
#                     break

#                 frame_queue.task_done()

#             except queue.Empty:
#                 # Kh√¥ng c√≥ frame n√†o trong h√†ng ƒë·ª£i, ti·∫øp t·ª•c v√≤ng l·∫∑p
#                 continue
#             except Exception as e:
#                 print(f"‚ùå [Lu·ªìng X·ª≠ L√Ω] L·ªói nghi√™m tr·ªçng: {e}")
#                 stop_event.set()
#                 break

#     finally:
#         if db_manager:
#             db_manager.save_all_databases()
#         cv2.destroyAllWindows()
#         print("--- [Lu·ªìng X·ª≠ L√Ω] H·ªÜ TH·ªêNG ƒê√É D·ª™NG ---")


# # --- [THAY ƒê·ªîI] H√†m main() m·ªõi: ƒêi·ªÅu ph·ªëi c√°c lu·ªìng ---
# def main():
#     """
#     H√†m main ch√≠nh ƒë·ªÉ kh·ªüi t·∫°o v√† qu·∫£n l√Ω c√°c lu·ªìng.
#     """
#     frame_queue = queue.Queue(maxsize=FRAME_QUEUE_MAX_SIZE)
#     stop_event = threading.Event()
#     zmq_context = zmq.Context()

#     # T·∫°o v√† kh·ªüi ch·∫°y c√°c lu·ªìng
#     network_t = threading.Thread(target=network_receiver_worker, args=(zmq_context, stop_event, frame_queue), daemon=True)
#     processing_t = threading.Thread(target=processing_loop, args=(frame_queue, stop_event), daemon=True)
    
#     print("üöÄ B·∫Øt ƒë·∫ßu kh·ªüi ch·∫°y c√°c lu·ªìng...")
#     network_t.start()
#     processing_t.start()

#     try:
#         # Gi·ªØ lu·ªìng ch√≠nh s·ªëng ƒë·ªÉ b·∫Øt t√≠n hi·ªáu Ctrl+C
#         # Ho·∫∑c ch·ªù cho ƒë·∫øn khi lu·ªìng x·ª≠ l√Ω k·∫øt th√∫c (do nh·∫•n 'q')
#         processing_t.join()
#     except KeyboardInterrupt:
#         print("‚ÑπÔ∏è B·∫Øt ƒë∆∞·ª£c t√≠n hi·ªáu Ctrl+C, g·ª≠i t√≠n hi·ªáu d·ª´ng...")
#         stop_event.set()

#     # ƒê·∫£m b·∫£o c√°c lu·ªìng ƒë√£ d·ª´ng ho√†n to√†n
#     network_t.join(timeout=2)
    
#     # D·ªçn d·∫πp
#     zmq_context.term()
#     print("‚úÖ T·∫•t c·∫£ c√°c lu·ªìng ƒë√£ k·∫øt th√∫c. Tho√°t ch∆∞∆°ng tr√¨nh.")


# if __name__ == "__main__":
#     main()
'''
import cv2
import queue
import threading
import asyncio
import sys
import os
import numpy as np
from ultralytics import YOLO
import zmq
import time

# --- C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
if BASE_DIR not in sys.path:
    sys.path.append(BASE_DIR)
# Th√™m th∆∞ m·ª•c utils v√†o path n·∫øu c·∫ßn
UTILS_DIR = os.path.join(BASE_DIR, 'utils')
if UTILS_DIR not in sys.path:
    sys.path.append(UTILS_DIR)

import config
from analyzer import Analyzer as ReidFaceAnalyzer
from attributes_analyzer import AttributesAnalyzer
from vector_database import VectorDatabase_Manager
from tracker import TrackManager
from draw import draw_tracked_objects

# --- C·∫•u h√¨nh ZMQ v√† X·ª≠ l√Ω Frame ---
ZMQ_IP = "localhost"
ZMQ_PORT = 5555
FRAME_QUEUE_MAX_SIZE = 100
FRAME_SKIP_RATE = 10 # ƒê·∫∑t l√† 1 ƒë·ªÉ x·ª≠ l√Ω t·∫•t c·∫£ frame cho vi·ªác ƒëo FPS ch√≠nh x√°c

# --- C√°c h√†m worker v√† ti·ªán √≠ch (Kh√¥ng thay ƒë·ªïi) ---
def is_image_quality_good(image, min_size=(64, 128), blur_threshold=80.0):
    if image is None or image.size == 0: return False
    h, w, _ = image.shape
    if w < min_size[0] or h < min_size[1]: return False
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    if cv2.Laplacian(gray, cv2.CV_64F).var() < blur_threshold: return False
    return True

def reid_face_worker(task_queue, result_queue, analyzer):
    """Worker cho lu·ªìng 1: Tr√≠ch xu·∫•t vector Re-ID v√† Face."""
    print("üöÄ Worker Re-ID/Face ƒë√£ b·∫Øt ƒë·∫ßu.")
    while True:
        try:
            track_id, image_crop = task_queue.get(block=True, timeout=1)
            if not is_image_quality_good(image_crop):
                task_queue.task_done()
                continue
            reid_vector = analyzer.extract_reid_feature(image_crop)
            face_vector, face_confidence = analyzer.extract_face_feature(image_crop)
            result_queue.put((track_id, reid_vector, face_vector, face_confidence))
            task_queue.task_done()
        except queue.Empty:
            continue
        except Exception as e:
            print(f"L·ªói trong worker Re-ID/Face: {e}")

def attribute_analysis_worker(task_queue, result_queue, analyzer):
    """Worker cho lu·ªìng 2: Ph√¢n t√≠ch thu·ªôc t√≠nh (gi·ªõi t√≠nh, qu·∫ßn √°o)."""
    print("üöÄ Worker ph√¢n t√≠ch thu·ªôc t√≠nh ƒë√£ b·∫Øt ƒë·∫ßu.")
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    while True:
        try:
            track_id, frame, bbox = task_queue.get(block=True, timeout=1)
            analysis_result = loop.run_until_complete(
                analyzer.analyze_person_by_bbox(frame, bbox, track_id)
            )
            result_queue.put((track_id, analysis_result))
            task_queue.task_done()
        except queue.Empty:
            continue
        except Exception as e:
            print(f"L·ªói trong worker ph√¢n t√≠ch thu·ªôc t√≠nh: {e}")

# --- Lu·ªìng nh·∫≠n d·ªØ li·ªáu t·ª´ ZMQ ---
def network_receiver_worker(context, stop_event, frame_queue):
    """
    Lu·ªìng chuy√™n nh·∫≠n d·ªØ li·ªáu t·ª´ ZMQ v√† ƒë·∫©y v√†o h√†ng ƒë·ª£i.
    T√≠ch h·ª£p logic b·ªè qua frame (frame skipping) v√† ƒëo FPS m·∫°ng.
    """
    socket = context.socket(zmq.SUB)
    socket.connect(f"tcp://{ZMQ_IP}:{ZMQ_PORT}")
    socket.setsockopt_string(zmq.SUBSCRIBE, '')
    
    print(f"‚úÖ [Lu·ªìng M·∫°ng] ƒê√£ k·∫øt n·ªëi t·ªõi tcp://{ZMQ_IP}:{ZMQ_PORT} v√† ƒëang l·∫Øng nghe...")
    
    frame_counter = 0
    # [TH√äM V√ÄO] Kh·ªüi t·∫°o bi·∫øn ƒë·ªÉ ƒëo FPS m·∫°ng
    fps_start_time = time.time()
    fps_frame_count = 0
    
    while not stop_event.is_set():
        try:
            if socket.poll(timeout=100):
                image_bytes = socket.recv()
                
                # [TH√äM V√ÄO] TƒÉng bi·∫øn ƒë·∫øm FPS m·∫°ng
                fps_frame_count += 1
                
                frame_counter += 1
                if frame_counter % FRAME_SKIP_RATE == 0:
                    try:
                        frame_queue.put_nowait(image_bytes)
                    except queue.Full:
                        print(f"‚ö†Ô∏è [Lu·ªìng M·∫°ng] H√†ng ƒë·ª£i frame ƒë·∫ßy. B·ªè qua frame.")
            
            # [TH√äM V√ÄO] T√≠nh to√°n v√† log FPS m·∫°ng m·ªói gi√¢y
            elapsed_time = time.time() - fps_start_time
            if elapsed_time >= 1.0:
                network_fps = fps_frame_count / elapsed_time
                print(f"üìä [Lu·ªìng M·∫°ng] FPS Nh·∫≠n: {network_fps:.2f}")
                # Reset ƒë·ªÉ ƒëo cho gi√¢y ti·∫øp theo
                fps_start_time = time.time()
                fps_frame_count = 0

        except zmq.ZMQError as e:
            print(f"‚ùå [Lu·ªìng M·∫°ng] L·ªói ZMQ: {e}")
            break
        except Exception as e:
            print(f"‚ùå [Lu·ªìng M·∫°ng] L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}")
            break
            
    print("üõë [Lu·ªìng M·∫°ng] ƒêang d·ª´ng...")
    socket.close()

# --- H√†m x·ª≠ l√Ω ch√≠nh ---
def processing_loop(frame_queue, stop_event):
    """
    Lu·ªìng chuy√™n x·ª≠ l√Ω ·∫£nh: l·∫•y ·∫£nh t·ª´ h√†ng ƒë·ª£i, ch·∫°y model,
    th·ª±c hi·ªán c√°c t√°c v·ª• ph√¢n t√≠ch v√† ƒëo FPS x·ª≠ l√Ω.
    """
    print("--- [Lu·ªìng X·ª≠ L√Ω] B·∫ÆT ƒê·∫¶U H·ªÜ TH·ªêNG TRACKING & PH√ÇN T√çCH ---")
    db_manager = None
    try:
        # --- 1. Kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn ---
        db_manager = VectorDatabase_Manager()
        reid_face_analyzer = ReidFaceAnalyzer(face_model_name="mobilefacenet")
        attributes_analyzer = AttributesAnalyzer()
        print("[Lu·ªìng X·ª≠ L√Ω] ƒêang t·∫£i models cho ph√¢n t√≠ch thu·ªôc t√≠nh, vui l√≤ng ƒë·ª£i...")
        asyncio.run(attributes_analyzer.load_models())
        print("‚úÖ [Lu·ªìng X·ª≠ L√Ω] T·∫£i models thu·ªôc t√≠nh ho√†n t·∫•t.")

        last_id = db_manager.get_max_person_id()
        track_manager = TrackManager(reid_face_analyzer, db_manager)
        track_manager.next_person_id = last_id + 1
        print(f"‚úÖ ID l·ªõn nh·∫•t trong CSDL: {last_id}. ID ti·∫øp theo: {last_id + 1}.")

        # --- 2. Thi·∫øt l·∫≠p x·ª≠ l√Ω ƒëa lu·ªìng ---
        reid_task_queue = queue.Queue(maxsize=100)
        reid_result_queue = queue.Queue()
        reid_worker = threading.Thread(target=reid_face_worker, args=(reid_task_queue, reid_result_queue, reid_face_analyzer), daemon=True)
        reid_worker.start()

        attribute_task_queue = queue.Queue(maxsize=50)
        attribute_result_queue = queue.Queue()
        attribute_worker = threading.Thread(target=attribute_analysis_worker, args=(attribute_task_queue, attribute_result_queue, attributes_analyzer), daemon=True)
        attribute_worker.start()

        # --- 3. Load model YOLO ---
        model = YOLO(config.PERSON_MODEL_PATH)
        
        print("\n‚úÖ [Lu·ªìng X·ª≠ L√Ω] H·ªá th·ªëng ƒë√£ s·∫µn s√†ng. Ch·ªù frame t·ª´ ZMQ...")
        
        # [TH√äM V√ÄO] Kh·ªüi t·∫°o bi·∫øn ƒë·ªÉ ƒëo FPS x·ª≠ l√Ω
        fps_start_time = time.time()
        fps_frame_count = 0
        processing_fps = 0

        # --- V√≤ng l·∫∑p ch√≠nh ---
        while not stop_event.is_set():
            try:
                image_bytes = frame_queue.get(timeout=1.0)
                
                np_array = np.frombuffer(image_bytes, dtype=np.uint8)
                frame = cv2.imdecode(np_array, cv2.IMREAD_COLOR)

                if frame is None:
                    print("‚ö†Ô∏è [Lu·ªìng X·ª≠ L√Ω] Kh√¥ng th·ªÉ gi·∫£i m√£ frame, b·ªè qua.")
                    continue

                # [TH√äM V√ÄO] TƒÉng bi·∫øn ƒë·∫øm FPS x·ª≠ l√Ω
                fps_frame_count += 1

                # Ch·∫°y model
                results = model.track(source=frame, show=False, conf=0.5, verbose=False, iou=0.5, classes=[0], tracker=config.TRACKER_CONFIG_PATH, stream=False, persist=True)
                
                for result in results:
                    track_ids, bboxes = [], []
                    if result.boxes.id is not None:
                        original_track_ids = result.boxes.id.int().cpu().tolist()
                        original_bboxes = result.boxes.xyxy.cpu().tolist()
                        for track_id, bbox in zip(original_track_ids, original_bboxes):
                            if (bbox[2] - bbox[0]) * (bbox[3] - bbox[1]) > config.MIN_BBOX_AREA and (bbox[2] - bbox[0]) * (bbox[3] - bbox[1]) < config.MAX_BBOX_AREA:
                                track_ids.append(track_id)
                                bboxes.append(bbox)

                    track_manager.update_tracks(track_ids, bboxes, frame, reid_task_queue, attribute_task_queue)
                    track_manager.process_analysis_results(reid_result_queue)
                    track_manager.process_attribute_results(attribute_result_queue)
                    
                    frame_with_drawings = draw_tracked_objects(frame, track_manager.tracked_objects)
                    
                    # [TH√äM V√ÄO] T√≠nh to√°n v√† hi·ªÉn th·ªã FPS x·ª≠ l√Ω l√™n frame
                    elapsed_time = time.time() - fps_start_time
                    if elapsed_time >= 1.0:
                        processing_fps = fps_frame_count / elapsed_time
                        # Reset ƒë·ªÉ ƒëo cho gi√¢y ti·∫øp theo
                        fps_start_time = time.time()
                        fps_frame_count = 0
                    
                    # V·∫Ω FPS l√™n m√†n h√¨nh
                    fps_text = f"Processing FPS: {processing_fps:.2f}"
                    cv2.putText(frame_with_drawings, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)

                    cv2.imshow("Tracking & Analysis System", frame_with_drawings)

                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print("‚ÑπÔ∏è Nh·∫•n 'q', g·ª≠i t√≠n hi·ªáu d·ª´ng...")
                    stop_event.set()
                    break

                frame_queue.task_done()

            except queue.Empty:
                continue
            except Exception as e:
                print(f"‚ùå [Lu·ªìng X·ª≠ L√Ω] L·ªói nghi√™m tr·ªçng: {e}")
                stop_event.set()
                break

    finally:
        if db_manager:
            db_manager.save_all_databases()
        cv2.destroyAllWindows()
        print("--- [Lu·ªìng X·ª≠ L√Ω] H·ªÜ TH·ªêNG ƒê√É D·ª™NG ---")


# --- H√†m main() m·ªõi: ƒêi·ªÅu ph·ªëi c√°c lu·ªìng ---
def main():
    """
    H√†m main ch√≠nh ƒë·ªÉ kh·ªüi t·∫°o v√† qu·∫£n l√Ω c√°c lu·ªìng.
    """
    frame_queue = queue.Queue(maxsize=FRAME_QUEUE_MAX_SIZE)
    stop_event = threading.Event()
    zmq_context = zmq.Context()

    # T·∫°o v√† kh·ªüi ch·∫°y c√°c lu·ªìng
    network_t = threading.Thread(target=network_receiver_worker, args=(zmq_context, stop_event, frame_queue), daemon=True)
    processing_t = threading.Thread(target=processing_loop, args=(frame_queue, stop_event), daemon=True)
    
    print("üöÄ B·∫Øt ƒë·∫ßu kh·ªüi ch·∫°y c√°c lu·ªìng...")
    network_t.start()
    processing_t.start()

    try:
        # Gi·ªØ lu·ªìng ch√≠nh s·ªëng ƒë·ªÉ b·∫Øt t√≠n hi·ªáu Ctrl+C
        processing_t.join()
    except KeyboardInterrupt:
        print("‚ÑπÔ∏è B·∫Øt ƒë∆∞·ª£c t√≠n hi·ªáu Ctrl+C, g·ª≠i t√≠n hi·ªáu d·ª´ng...")
        stop_event.set()

    # ƒê·∫£m b·∫£o c√°c lu·ªìng ƒë√£ d·ª´ng ho√†n to√†n
    network_t.join(timeout=2)
    
    # D·ªçn d·∫πp
    zmq_context.term()
    print("‚úÖ T·∫•t c·∫£ c√°c lu·ªìng ƒë√£ k·∫øt th√∫c. Tho√°t ch∆∞∆°ng tr√¨nh.")
 

if __name__ == "__main__":
    main()



